# *****************************************************************
#  Copyright 2011 MIT Lincoln Laboratory
#  Project:            SPAR
#  Authors:            OMD
#  Description:        Configuration for the set of variables we're going
#                      to use in the SPAR program.
#
#  Modifications:
#  Date          Name           Modification
#  ----          ----           ------------
#  13 Dec 2011   omd            Original Version
# *****************************************************************

"""
This module contains a number of Enums (see spar_python.common.enum)
which are used to represent the data values needed/produced/handled in the SPAR
project. In this module, we collect some information about these variables:

* Their names (though technically, these names are just aliases for int values
assigned by the Enum constructor),

* How to convert them into useful forms, like their string representation,

and so on. However, there are a number of ways in which these variables cannot
be treated uniformly:

* They will be of different types.

* Some of them will have completely independent distributions, while others
will be conditioned on the values of other variables.

* Their distributions will be learned from different sources. For example, an
number of them are going to be learned from the Census Bureau's PUMS data, while
others are drawn from other data-sources. And some are just plain made up.

Also, there are some important orderings on these variables:

* The order in which they should be generated by the DataGeneratorEngine,

* In some cases, the order in which they should be learned.

In order to handle all this non-uniformilty, this module is actually going to be
somewhat messy. And unfortunately, this messiness cannot be completely hidden
from the distribution-learning routines in learn_distributions.py. But a goal 
of this module is to hide this messiness from the rest of the code, particularly
instances of DataGeneratorEngine and the aggregators.

The current list of variables, with their types (Python classes), is as follows:


=============     =======================
Variable name     Type
==============    =======================
ID                int (64 bits)
FIRST_NAME        String
LAST_NAME         String
SSN               String
ZIP_CODE          String
CITY              String
STREET_ADDRESS    String
STATE             Enum
SEX               Enum
AGE               int
RACE              Enum
MARITAL_STATUS    Enum
GRADE_ENROLLED    Enum
EDUCATION         Enum
CITIZENSHIP       Enum
INCOME            int
MILITARY_SERVICE  Enum
LANGUAGE          Enum
HOURS_WORKED      int
WEEKS_WORKED      int
FOO               long long (64-bit)
LAST_UPDATED      long (32-bit)
NOTES1            See text_distribution.py
NOTES2            See text_distribution.py
NOTES3            See text_distribution.py
NOTES4            See text_distribution.py
DOB               datetime.date
XML               See xml_generator.py
FINGERPRINT       bytearray
=============     =======================

Writers of aggregators can rely on these types. For example, they can rely on
the assumption that if row_dict is a row-dictionary provided by 
DataGeneratorEngine, then

  row_dict[spar_variables.VARS.DOB] 
  
will return a datetime.date object (assuming, of course, that the row_dict
contains a value for DOB at all).

"""



import spar_python.data_generation.learning.pums_variables as pv
from spar_python.data_generation.learning.pums_record_handler import PUMSRecordHandler
from spar_python.common.enum import Enum
import collections
from spar_python.common.distributions.text_generator import TextGenerator
import csv
import operator

#############################################################################
#
# This is the master list of all SPAR variables
#
##############################################################################
VARS = Enum('FIRST_NAME',
            'LAST_NAME',
            'SSN',
            'ZIP_CODE',
            'CITY',
            'STREET_ADDRESS',
            'NOTES1',
            'NOTES2',
            'NOTES3',
            'NOTES4',
            'ID',
            'DOB',
            'FINGERPRINT',
            'STATE', 
            'SEX', 
            'AGE', 
            'RACE', 
            'MARITAL_STATUS',
            'GRADE_ENROLLED', 
            'EDUCATION',
            'CITIZENSHIP', 
            'INCOME',   
            'MILITARY_SERVICE',
            'LANGUAGE', 
            'HOURS_WORKED', 
            'WEEKS_WORKED',
            'FOO',
            'LAST_UPDATED',
            'XML')

# Mapping from the name in the schema file to the value in the
# vars enum. This isn't perfect, but it does have the following nice
# properties:
#
# 1) If the order in the schema file changes this will change
#    accordingly.
# 2) If fields get deleted this still works fine
# 3) If new fields get added this will throw an exception rather
#    than generating the wrong stuff.
sql_info = {        VARS.ID         : ('id','integer'),
                    VARS.FIRST_NAME : ('fname','string'),
                    VARS.LAST_NAME  : ('lname','string'),
                    VARS.SSN        : ('ssn','string'),
                    VARS.ZIP_CODE   : ('zip','string'),
                    VARS.CITY       : ('city','string'),
                    VARS.STREET_ADDRESS : ('address','string'),
                    VARS.STATE     : ('state','enum'),
                    VARS.SEX       : ('sex','enum'),
                    VARS.AGE       : ('age','integer'),
                    VARS.RACE      : ('race','enum'),
                    VARS.MARITAL_STATUS : ('marital_status','enum'),
                    VARS.GRADE_ENROLLED : ('school_enrolled','enum'),
                    VARS.EDUCATION : ('education','enum'),
                    VARS.CITIZENSHIP : ('citizenship','enum'),
                    VARS.INCOME   : ('income','integer'),
                    VARS.MILITARY_SERVICE : ('military_service','enum'),
                    VARS.LANGUAGE : ('language','enum'),
                    VARS.HOURS_WORKED: ('hours_worked_per_week','integer'),
                    VARS.WEEKS_WORKED: ('weeks_worked_last_year','integer'),
                    VARS.FOO: ('foo','integer'),
                    VARS.LAST_UPDATED : ('last_updated','integer'),
                    VARS.NOTES1 : ('notes1','string'),
                    VARS.NOTES2 : ('notes2','string'),
                    VARS.NOTES3 : ('notes3','string'),
                    VARS.NOTES4 : ('notes4','string'),
                    VARS.DOB : ('dob','date'),
                    VARS.XML: ('xml', 'string'),
                    VARS.FINGERPRINT : ('fingerprint', 'blob')}


def sql_name_to_enum(sql_name):
    '''
    Maps between the internal representation and the query_input representation
    which is also the sql representation of fields. 
    '''
    for (enum, (name,_)) in sql_info.iteritems():
        if name == sql_name:
            return enum
    raise KeyError(sql_name)

def enum_to_sql_name(enum):
    '''
    Maps between the enum and the column name
    '''
    sql_name = sql_info[enum][0]
    return sql_name
    

# Divide the various vars into their types, so that we can sanitize each
# in the right way.

RAW_VARS = [VARS.NOTES1, VARS.NOTES2, VARS.NOTES3, VARS.NOTES4, 
            VARS.FINGERPRINT]

INT_VARS = [VARS.ID, VARS.AGE, VARS.INCOME, VARS.HOURS_WORKED, 
            VARS.WEEKS_WORKED, VARS.FOO, VARS.LAST_UPDATED]

ENUM_VARS = [VARS.STATE, VARS.SEX, VARS.RACE, VARS.MARITAL_STATUS, 
             VARS.GRADE_ENROLLED, VARS.EDUCATION, VARS.CITIZENSHIP, 
             VARS.MILITARY_SERVICE, VARS.LANGUAGE]

REMAPABLE_VARS = [VARS.FIRST_NAME, VARS.LAST_NAME, VARS.CITY, VARS.ZIP_CODE]


# Not included in the above lists:
# * VARS.SSN
# * VARS.STREET_ADDRESS
# * VARS.XML
# * VARS.DOB


#############################################################################
#
# Information needed to calculate row width
#
#############################################################################

field_type_width = {'BIGINT'            : lambda length: 8,
                    'BIGINT UNSIGNED'   : lambda length: 8,
                    'INT'               : lambda length: 4,
                    'INT UNSIGNED'      : lambda length: 4,
                    'CHAR'              : lambda length: length,
                    'DATE'              : lambda length: 3,
                    'ENUM'              : lambda length: 1,
                    'SMALLINT'          : lambda length: 2,
                    'SMALLINT UNSIGNED' : lambda length: 2,
                    'TINYINT'           : lambda length: 1,
                    'TINYINT UNSIGNED'  : lambda length: 1,
                    'TEXT'              : lambda length: 4 + length,
                    'VARCHAR'           : lambda length: 2 + length,
                    'BLOB'              : lambda length: length }

def row_width(schema_file):
    schema_f = open(schema_file, 'r')
    reader = csv.DictReader(schema_f)
    sum_total = 0
    for row in reader:
        sum_total += field_type_width[row['type']](int(row['length']))
    schema_f.close()
    return sum_total

#############################################################################
#
# Information needed for compound query generation
#
#############################################################################

#key is proportion of the total db-size that it can maximally represent
pdf_to_fields = { 
      0.00001 : [ VARS.DOB,  VARS.ZIP_CODE, VARS.INCOME, VARS.STREET_ADDRESS, 
                 VARS.FOO, VARS.LAST_NAME],
      0.0001 :  [ VARS.FIRST_NAME,  VARS.CITY,  VARS.ZIP_CODE, VARS.INCOME, 
                 VARS.LAST_NAME, VARS.FOO],
      0.001  :  [ VARS.FIRST_NAME,  VARS.CITY,  VARS.ZIP_CODE, VARS.LAST_NAME, 
                 VARS.FOO],
      0.01   :  [ VARS.FIRST_NAME, VARS.STATE,  VARS.RACE, VARS.LANGUAGE, 
                 VARS.GRADE_ENROLLED,  VARS.CITIZENSHIP,  VARS.MILITARY_SERVICE,
                 VARS.FOO, VARS.LAST_NAME],
      0.1    :  [ VARS.STATE,  VARS.RACE,  VARS.GRADE_ENROLLED,
                 VARS.CITIZENSHIP,  VARS.MILITARY_SERVICE, VARS.LANGUAGE],
      0.5    :  [ VARS.SEX],
      1.0    :  [ VARS.SEX,  VARS.RACE,  VARS.MARITAL_STATUS,  VARS.GRADE_ENROLLED, 
                 VARS.CITIZENSHIP,  VARS.MILITARY_SERVICE, VARS.HOURS_WORKED,  
                 VARS.WEEKS_WORKED, VARS.LANGUAGE]  }

def field_to_min_pdf(field_name):
    for (value, list) in sorted(pdf_to_fields.iteritems(), reverse=False):
        if field_name in list:
            return value
    raise KeyError

def field_to_max_pdf(field_name):
    for (value, list) in sorted(pdf_to_fields.iteritems(), reverse=True):
        if field_name in list:
            return value
    raise KeyError

field_dependencies = {
                   VARS.SEX :  [],
                   VARS.CITIZENSHIP :[],
                   VARS.AGE : [],
                   VARS.FOO : [],
                   VARS.LAST_NAME : [],
                   VARS.STREET_ADDRESS : [VARS.CITIZENSHIP, VARS.RACE, VARS.STATE, VARS.ZIP_CODE],
                   VARS.LANGUAGE : [VARS.CITIZENSHIP, VARS.RACE], 
                   VARS.INCOME : [ VARS.AGE],
                   VARS.RACE : [ VARS.CITIZENSHIP],
                   VARS.STATE : [ VARS.RACE],
                   VARS.WEEKS_WORKED : [ VARS.AGE],
                   VARS.HOURS_WORKED : [ VARS.WEEKS_WORKED], 
                   VARS.MILITARY_SERVICE : [ VARS.AGE,  VARS.SEX],
                   VARS.MARITAL_STATUS : [ VARS.MILITARY_SERVICE,  VARS.AGE],
                   VARS.GRADE_ENROLLED : [ VARS.MILITARY_SERVICE,  VARS.AGE],
                   VARS.FIRST_NAME : [ VARS.SEX],
                   VARS.ZIP_CODE : [ VARS.STATE],
                   VARS.CITY : [ VARS.ZIP_CODE],
                   VARS.DOB : [],
        }

field_dependencies_cycles = [
     [ VARS.CITIZENSHIP,  VARS.RACE,  VARS.STATE,  VARS.ZIP_CODE, 
             VARS.CITY, VARS.STREET_ADDRESS, VARS.LANGUAGE, VARS.LAST_NAME,
             VARS.FOO],
     [ VARS.SEX,  VARS.FIRST_NAME, VARS.LAST_NAME, VARS.FOO],
     [ VARS.DOB,  VARS.WEEKS_WORKED,  VARS.HOURS_WORKED, VARS.INCOME, 
      VARS.LAST_NAME, VARS.FOO],      
     [ VARS.DOB,  VARS.SEX,  VARS.FIRST_NAME,  VARS.MILITARY_SERVICE, 
              VARS.MARITAL_STATUS,  VARS.GRADE_ENROLLED, VARS.LAST_NAME,
              VARS.FOO], 
     [ VARS.SEX,  VARS.DOB,  VARS.MILITARY_SERVICE,  VARS.MARITAL_STATUS, 
             VARS.GRADE_ENROLLED, VARS.FOO, VARS.LAST_NAME]]

performer_allowed_fields = { 'IBM1' : [VARS.SEX, VARS.CITIZENSHIP, VARS.INCOME,
                                       VARS.RACE, VARS.STATE, VARS.WEEKS_WORKED, 
                                       VARS.HOURS_WORKED, VARS.MILITARY_SERVICE, 
                                       VARS.MARITAL_STATUS, VARS.GRADE_ENROLLED, 
                                       VARS.FIRST_NAME, VARS.ZIP_CODE, VARS.CITY, 
                                       VARS.DOB, VARS.LANGUAGE, VARS.LAST_NAME,
                                       VARS.STREET_ADDRESS, VARS.FOO],
                             "COL" : [VARS.SEX, VARS.CITIZENSHIP, VARS.INCOME,
                                       VARS.RACE, VARS.STATE, VARS.WEEKS_WORKED, 
                                       VARS.HOURS_WORKED, VARS.MILITARY_SERVICE, 
                                       VARS.MARITAL_STATUS, VARS.GRADE_ENROLLED, 
                                       VARS.FIRST_NAME, VARS.ZIP_CODE, VARS.CITY, 
                                       VARS.DOB, VARS.LANGUAGE, VARS.LAST_NAME,
                                       VARS.STREET_ADDRESS, VARS.FOO],
                             "LL" : [VARS.SEX, VARS.CITIZENSHIP, VARS.INCOME,
                                       VARS.RACE, VARS.STATE, VARS.WEEKS_WORKED, 
                                       VARS.HOURS_WORKED, VARS.MILITARY_SERVICE, 
                                       VARS.MARITAL_STATUS, VARS.GRADE_ENROLLED, 
                                       VARS.FIRST_NAME, VARS.ZIP_CODE, VARS.CITY, 
                                       VARS.DOB, VARS.LANGUAGE, VARS.LAST_NAME,
                                       VARS.STREET_ADDRESS, VARS.FOO],
                            "IBM2" : [VARS.INCOME, VARS.STATE, VARS.RACE,
                                      VARS.WEEKS_WORKED, VARS.HOURS_WORKED, 
                                      VARS.MILITARY_SERVICE, VARS.CITIZENSHIP,
                                      VARS.FIRST_NAME, VARS.ZIP_CODE, VARS.CITY, 
                                      VARS.DOB, VARS.STATE]}

fields_not_in_skinny = [VARS.STREET_ADDRESS, VARS.LAST_NAME, VARS.LANGUAGE]

#############################################################################
#
# Variable orderings and sources
#
#############################################################################


# And now the messiness begins. We want to define the order in which these
# variables should be generated by the DataGeneratorEngine, which depends
# on two factors:
#
# 1) Variables from conditioned distributions should only be generated
# after the variables they are conditioned on.
#
# 2) After that, cheap variables should be generated before expensive
# variables.
#
# So, let's begin with the PUMS variables and how they depend on each other. The
# way to read this list is that entry (VAR1, [VAR2, VAR3]) is that VAR1 should
# depend on VAR2 and VAR3 (jointly).
#
# Note: This list is fragile. In particular, the way in which we
# encode and use conditional probabilities requires that each independent
# variable should be limited to a small number of possible values.
# VARS.AGE is okay, since it is limited to 100 or so values. Likewise,
# most of the numberated variables (VAR.CITIZENSHIP, VARS.STATE) are okay.
# VARS.INCOME is probably bad.

# Note: list derived from Oliver's neural-net learning, but tweaked
# to limit number of independent vars and remove INCOME as an independent var
PUMS_VARS_DEPS = [(VARS.SEX, []),
                  (VARS.CITIZENSHIP, []),
                  (VARS.AGE, []),
                  (VARS.INCOME, [VARS.AGE]),
                  (VARS.RACE, [VARS.CITIZENSHIP]),
                  (VARS.STATE, [VARS.RACE]),
                  (VARS.WEEKS_WORKED, [VARS.AGE]),
                  (VARS.HOURS_WORKED, [VARS.WEEKS_WORKED]), 
                  (VARS.MILITARY_SERVICE, [VARS.AGE, VARS.SEX]),
                  (VARS.MARITAL_STATUS, [VARS.MILITARY_SERVICE, VARS.AGE]),
                  (VARS.GRADE_ENROLLED, [VARS.MILITARY_SERVICE, VARS.AGE]),
                  (VARS.EDUCATION, [VARS.MILITARY_SERVICE, VARS.AGE]),
                  (VARS.LANGUAGE, [VARS.CITIZENSHIP, VARS.RACE])]


# With this, we define the order in which variables should be generated by the
# data-generator. This list is also fragile, for the two reasons mentioned 
# above:
#
# 1) When VAR1 depends on VAR2, we need to generate VAR2 first.
#
# 2) The data-generator is free to drop elements from the *end* of this list
# if they are not needed for output, but cannot drop from the beginning or the
# middle. So, the most-expensive items should go at the end.

# PUMS vars 
PUMS_ORDER = [var for (var, _) in PUMS_VARS_DEPS]

# Names -- depends on sex (which is in PUMS vars)
NAMES_ORDER = [VARS.FIRST_NAME, VARS.LAST_NAME] 

# These ones depend on VARS.STATE, which are in the PUMS vars
LOCATION_ORDER =  [VARS.ZIP_CODE, VARS.CITY, VARS.STREET_ADDRESS] 

# DOB depends on AGE, and LAST_UPDATED depends on DOB
TEMPORAL_VARS_ORDER = [VARS.DOB, VARS.LAST_UPDATED]

# These next ones are actually independent of any prior ones
# but are cheap.
MISC_ORDER = [VARS.SSN, VARS.FOO, VARS.XML] 

# Fingerprints are expensive, but not as expensive as texts
# Text fields are expensive, so put them last and from shortest to longest
COSTLY_ORDER = [VARS.FINGERPRINT, VARS.NOTES4, VARS.NOTES3, 
                VARS.NOTES2, VARS.NOTES1]


VAR_GENERATION_ORDER = PUMS_ORDER + NAMES_ORDER + LOCATION_ORDER \
            + TEMPORAL_VARS_ORDER + MISC_ORDER + COSTLY_ORDER






#############################################################################
#
# PUMS-specific code
#
#######################################################################



# Please note that for simplicity, the Enums in this module may reduce the
# complexity of the underlying census data by eliminating a number of options.
# The census data for race, in particular, is extremely complex and not easily
# expressed as a single value. In this module, we reduce it to nine over-
# simplified options. This should not be taken as a statement of any kind on the
# part of Lincoln Laboratory, but merely as a necessary tactic for controlling
# complexity.


# Note that the census skips some values for no apparent reason (e.g. 7 is not
# used) so I explicitly map values to numbers here.
STATES = Enum(
        Alabama = 1, Alaska = 2, Arizona = 4, Arkansas = 5,
        California = 6, Colorado = 8, Connecticut = 9, Delaware = 10,
        District_of_Columbia = 11, Florida = 12, Georgia = 13, Hawaii = 15,
        Idaho = 16, Illinois = 17, Indiana = 18, Iowa = 19, Kansas = 20,
        Kentucky = 21, Louisiana = 22, Maine = 23, Maryland = 24,
        Massachusetts = 25, Michigan = 26, Minnesota = 27, Mississippi = 28,
        Missouri = 29, Montana = 30, Nebraska = 31, Nevada = 32,
        New_Hampshire = 33, New_Jersey = 34, New_Mexico = 35, New_York = 36,
        North_Carolina = 37, North_Dakota = 38, Ohio = 39, Oklahoma = 40,
        Oregon = 41, Pennsylvania = 42, Rhode_Island = 44,
        South_Carolina = 45, South_Dakota = 46, Tennessee = 47, Texas = 48,
        Utah = 49, Vermont = 50, Virginia = 51, Washington = 53,
        West_Virginia = 54, Wisconsin = 55, Wyoming = 56, Puerto_Rico = 72)
STATE_PARSER = pv.EnumParser(STATES, 9, 11, source = pv.RECORD_SOURCE.HOUSEHOLD)
STATE_MANIPULATOR = pv.CategoricalManipulator(STATES,
        'State in which this person lives.')

SEX = Enum(Male = 1, Female = 2)
SEX_PARSER = pv.EnumParser(SEX, 22, 23)
SEX_MANIPULATOR = pv.CategoricalManipulator(SEX, "Person's gender")

EDUCATION = Enum(
    not_in_universe_less_than_three = 0,
    no_education = 1, Nursery_school_to_4th_grade = 2,
    grade_5_to_6 = 3, grade_7_to_8 = 4,
    grade_9 = 5, grade_10 = 6, grade_11 = 7,
    grade_12_no_diploma = 8, High_school_graduate = 9,
    Less_than_1_year_college = 10,
    One_or_more_years_of_college_no_degree = 11,
    Associate_degree = 12, Bachelors_degree = 13, Masters_degree = 14,
    Professional_degree = 15, Doctorate_degree = 16)
EDUCATION_PARSER = pv.EnumParser(EDUCATION, 52, 54)
EDUCATION_MANIPULATOR = pv.OrdinalManipulator(EDUCATION,
        'Education level attained by this  person')

# Note that age's are "top-coded" at 90 meaning any individual whose age is > 90
# is simply shown as having an age == the median over-90 age for their state.
#
# TODO(odain): Age is top coded and we're not handling that correctly yet.
AGE_PARSER = pv.IntParser(24, 26)
AGE_MANIPULATOR = pv.IntManipulator('Age. Note: top-coded to age 90.')

# Race coding in the PUMS data is very complex with multiple race fields that
# allow you to specify increasingly detailed info (e.g. 1st group says native
# american, 2nd says primary tribe, etc.). For this data we use a very
# simplified version so we require a custom parser that collapses some
# categories, etc.
RACE = Enum('White', 'African_American', 'American_Indian', 'Alaska_Native',
        'Asian', 'Hawaiian', 'Other', 'Two_or_More_Races')
class RaceParser(pv.IntParser):
    # How census values map to our enum values. It's mostly 1-1 except that
    # in addition to the american indian and alaska native categories the
    # census has a category for "American Indian and Alaska Native tribes
    # specified, and American Indian or Alaska Native, not specified, and no
    # other races" which we just map to American_Indian
    CENSUS_TO_ENUM_MAP = {1: RACE.White, 2: RACE.African_American,
            3: RACE.American_Indian, 4: RACE.Alaska_Native,
            5: RACE.American_Indian, 6: RACE.Asian,
            7: RACE.Hawaiian, 8: RACE.Other, 9: RACE.Two_or_More_Races}

    def __init__(self):
        pv.IntParser.__init__(self, 37, 38)

    def parse(self, line):
        value = pv.IntParser.parse(self, line)

        return self.CENSUS_TO_ENUM_MAP[value]

RACE_PARSER = RaceParser()
RACE_MANIPULATOR = pv.CategoricalManipulator(RACE, 'Ethnicity of the person')

MARITAL_STATUS = Enum(
    Married = 1, Widowed = 2, Divorced = 3,
    Separated = 4, Never_Married = 5)
MARITAL_STATUS_PARSER = pv.EnumParser(MARITAL_STATUS, 43, 44)
MARITAL_STATUS_MANIPULATOR = pv.CategoricalManipulator(MARITAL_STATUS,
        'Marital Status')


GRADE_ENROLLED = Enum(
    Not_In_School = 0, Nursery_or_Preschool = 1, Kindergarten = 2,
    Grade_1_to_4 = 3, Grade_5_to_8 = 4, Grade_9_to_12 = 5,
    College_undergraduate = 6, Graduate_or_professional_school = 7)
GRADE_ENROLLED_PARSER = pv.EnumParser(GRADE_ENROLLED, 50, 51)
GRADE_ENROLLED_MANIPULATOR = pv.OrdinalManipulator(GRADE_ENROLLED,
        'What grade, if any, the person is currently in at school')

CITIZENSHIP = Enum(
   Yes_Born_In_US = 1, Yes_Born_In_US_Territory = 2,
   Yes_Born_Abroad_US_Parents = 3, Yes_Naturalized = 4,
   No = 5)
CITIZENSHIP_PARSER = pv.EnumParser(CITIZENSHIP, 75, 76)
CITIZENSHIP_MANIPULATOR = pv.CategoricalManipulator(
      CITIZENSHIP, 'US Citizen Status')

# TODO(odain): Income is top and bottom coded. Not handling that correctly yet.
INCOME_PARSER = pv.IntParserWithDefault(296, 303, default_value = 0)
INCOME_MANIPULATOR = pv.IntManipulator('Total income. Note: top and '
   'bottom coded')

MILITARY_SERVICE = Enum(
        Under_17 = 0, Active_Duty = 1, Previous_Active_Duty = 2,
        Training = 3, Never_Active_Duty = 4)
MILITARY_SERVICE_PARSER = pv.EnumParser(MILITARY_SERVICE, 137, 138)
MILITARY_SERVICE_MANIPULATOR = pv.CategoricalManipulator(
        MILITARY_SERVICE, 'Military Service Status')

LANGUAGE = Enum.from_dict_list(
        {'NOT_IN_UNIVERSE': 0, 'ENGLISH': 1, 'NOT_SPECIFIED': 998,
    'NOOTKA': 831, 'JAMAICAN_CREOLE': 601, 'KRIO': 602,
    'HAWAIIAN_PIDGIN': 603, 'PIDGIN': 604, 'GULLAH': 605,
    'SARAMACCA': 606, 'GERMAN': 607, 'PENNSYLVANIA_DUTCH': 608,
    'YIDDISH': 609, 'DUTCH': 610, 'AFRIKAANS': 611, 'FRISIAN': 612,
    'LUXEMBOURGIAN': 613, 'SWEDISH': 614, 'DANISH': 615, 'NORWEGIAN': 616,
    'ICELANDIC': 617, 'FAROESE': 618, 'ITALIAN': 619, 'FRENCH': 620,
    'PROVENCAL': 621, 'PATOIS': 622, 'FRENCH_CREOLE': 623, 'CAJUN': 624,
    'SPANISH': 625, 'CATALONIAN': 626, 'LADINO': 627, 'PACHUCO': 628,
    'PORTUGUESE': 629, 'PAPIA_MENTAE': 630, 'RUMANIAN': 631,
    'RHAETO_ROMANIC': 632,
    'WELSH': 633, 'BRETON': 634, 'IRISH_GAELIC': 635, 'SCOTTIC_GAELIC': 636,
    'GREEK': 637, 'ALBANIAN': 638, 'RUSSIAN': 639, 'BIELORUSSIAN': 640,
    'UKRAINIAN': 641, 'CZECH': 642, 'KASHUBIAN': 643, 'LUSATIAN': 644,
    'POLISH': 645, 'SLOVAK': 646, 'BULGARIAN': 647, 'MACEDONIAN': 648,
    'SERBOCROATIAN': 649, 'CROATIAN': 650, 'SERBIAN': 651, 'SLOVENE': 652,
    'LITHUANIAN': 653, 'LETTISH': 654, 'ARMENIAN': 655, 'PERSIAN': 656,
    'PASHTO': 657, 'KURDISH': 658, 'BALOCHI': 659, 'TADZHIK': 660,
    'OSSETE': 661, 'INDIA': 662, 'HINDI': 663, 'BENGALI': 664,
    'PANJABI': 665, 'MARATHI': 666,
    'GUJARATHI': 667, 'BIHARI': 668, 'RAJASTHANI': 669, 'ORIYA': 670,
    'URDU': 671,
    'ASSAMESE': 672, 'KASHMIRI': 673, 'NEPALI': 674, 'SINDHI': 675,
    'PAKISTAN': 676,
    'SINHALESE': 677, 'ROMANY': 678, 'FINNISH': 679, 'ESTONIAN': 680,
    'LAPP': 681,
    'HUNGARIAN': 682, 'OTHER_URALIC_LANGUAGES': 683, 'CHUVASH': 684,
    'KARAKALPAK': 685, 'KAZAKH': 686, 'KIRGHIZ': 687, 'KARACHAY': 688,
    'UIGHUR': 689, 'AZERBAIJANI': 690, 'TURKISH': 691, 'TURKMEN': 692,
    'YAKUT': 693,
    'MONGOLIAN': 694, 'TUNGUS': 695, 'CAUCASIAN': 696, 'BASQUE': 697,
    'DRAVIDIAN': 698, 'BRAHUI': 699, 'GONDI': 700, 'TELUGU': 701,
    'KANNADA': 702, 'MALAYALAM': 703, 'TAMIL': 704, 'KURUKH': 705, 'MUNDA': 706,
    'BURUSHASKI': 707, 'CHINESE': 708, 'HAKKA': 709, 'KAN,_HSIANG': 710,
    'CANTONESE': 711, 'MANDARIN': 712, 'FUCHOW': 713, 'FORMOSAN': 714,
    'WU': 715, 'TIBETAN': 716, 'BURMESE': 717, 'KAREN': 718, 'KACHIN': 719,
    'THAI': 720, 'MIAO_YAO,_MIEN': 721, 'MIAO,_HMONG': 722, 'JAPANESE': 723,
    'KOREAN': 724, 'LAOTIAN': 725, 'MON_KHMER,_CAMBODIAN': 726,
    'VIETNAMESE': 728, 'MUONG': 729, 'BUGINESE': 730, 'MOLUCCAN': 731,
    'INDONESIAN': 732, 'ACHINESE': 733, 'BALINESE': 734, 'CHAM': 735,
    'JAVANESE': 736, 'MADURESE': 737, 'MALAGASY': 738, 'MALAY': 739,
    'MINANGKABAU': 740, 'SUNDANESE': 741, 'TAGALOG': 742, 'BISAYAN': 743,
    'SEBUANO': 744, 'PANGASINAN': 745, 'ILOCANO': 746, 'BIKOL': 747,
    'PAMPANGAN': 748, 'GORONTALO': 749, 'MICRONESIAN': 750, 'CAROLINIAN': 751,
    'CHAMORRO': 752, 'GILBERTESE': 753, 'KUSAIEAN': 754, 'MARSHALLESE': 755,
    'MOKILESE': 756, 'MORTLOCKESE': 757, 'NAURUAN': 758, 'PALAU': 759,
    'PONAPEAN': 760, 'TRUKESE': 761, 'ULITHEAN': 762, 'WOLEAI_ULITHI': 763,
    'YAPESE': 764, 'MELANESIAN': 765, 'POLYNESIAN': 766, 'SAMOAN': 767,
    'TONGAN': 768, 'NIUEAN': 769, 'TOKELAUAN': 770, 'FIJIAN': 771,
    'MARQUESAN': 772, 'RAROTONGAN': 773, 'MAORI': 774, 'NUKUORO': 775,
    'HAWAIIAN': 776, 'ARABIC': 777, 'HEBREW': 778, 'SYRIAC': 779,
    'AMHARIC': 780, 'BERBER': 781, 'CHADIC': 782, 'CUSHITE': 783,
    'SUDANIC': 784, 'NILOTIC': 785, 'NILO_HAMITIC': 786, 'NUBIAN': 787,
    'SAHARAN': 788, 'NILO_SAHARAN': 789, 'KHOISAN': 790, 'SWAHILI': 791,
    'BANTU': 792, 'MANDE': 793, 'FULANI': 794, 'GUR': 795,
    'KRU__IBO_YORUBA': 796, 'EFIK': 797, 'MBUM_AND_RELATED': 798,
    'AFRICAN': 799, 'ALEUT': 800,
    'PACIFIC_GULF_YUPIK': 801, 'ESKIMO': 802, 'INUPIK': 803,
    'SAINT_LAWRENCE_ISLAND_YUPIK': 804, 'YUPIK': 805, 'ALGONQUIAN': 806,
    'ARAPAHO': 807, 'ATSINA': 808, 'BLACKFOOT': 809, 'CHEYENNE': 810,
    'CREE': 811, 'DELAWARE': 812, 'FOX': 813, 'KICKAPOO': 814,
    'MENOMINI': 815, 'FRENCH_CREE': 816, 'MIAMI': 817, 'MICMAC': 818,
    'OJIBWA': 819, 'OTTAWA': 820, 'PASSAMAQUODDY': 821, 'PENOBSCOT': 822,
    'ABNAKI': 823, 'POTAWATOMI': 824, 'SHAWNEE': 825, 'WIYOT': 826,
    'YUROK': 827, 'KUTENAI': 828, 'MAKAH': 829, 'KWAKIUTL': 830,
    'LOWER_CHEHALIS': 833, 'UPPER_CHEHALIS': 834, 'CLALLAM': 835,
    'COEUR_DALENE': 836, 'COLUMBIA': 837, 'COWLITZ': 838, 'SALISH': 839,
    'NOOTSACK': 840, 'OKANOGAN': 841, 'PUGET_SOUND_SALISH': 842,
    'QUINAULT': 843,
    'TILLAMOOK': 844, 'TWANA': 845, 'HAIDA': 846, 'ATHAPASCAN': 847,
    'AHTENA': 848, 'HAN': 849, 'INGALIT': 850, 'KOYUKON': 851,
    'KUCHIN': 852, 'UPPER_KUSKOKWIM': 853, 'TANAINA': 854, 'TANANA': 855,
    'TANACROSS': 856, 'UPPER_TANANA': 857, 'TUTCHONE': 858, 'CHASTA_COSTA': 859,
    'HUPA': 860, 'OTHER_ATHAPASCAN_EYAK_LANGUAGES': 861, 'APACHE': 862,
    'KIOWA': 863, 'NAVAHO': 864, 'EYAK': 865, 'TLINGIT': 866,
    'MOUNTAIN_MAIDU': 867, 'NORTHWEST_MAIDU': 868, 'SOUTHERN_MAIDU': 869,
    'COAST_MIWOK': 870, 'PLAINS_MIWOK': 871, 'SIERRA_MIWOK': 872,
    'NOMLAKI': 873,
    'PATWIN': 874, 'WINTUN': 875, 'FOOTHILL_NORTH_YOKUTS': 876,
    'TACHI': 877, 'SANTIAM': 878, 'SIUSLAW': 879, 'KLAMATH': 880,
    'NEZ_PERCE': 881,
    'SAHAPTIAN': 882, 'UPPER_CHINOOK': 883, 'TSIMSHIAN': 884, 'ACHUMAWI': 885,
    'ATSUGEWI': 886, 'KAROK': 887, 'POMO': 888, 'SHASTAN': 889, 'WASHO': 890,
    'UP_RIVER_YUMAN': 891, 'COCOMARICOPA': 892, 'MOHAVE': 893,
    'YUMA': 894, 'DIEGUENO': 895, 'DELTA_RIVER_YUMAN': 896, 'UPLAND_YUMAN': 897,
    'HAVASUPAI': 898, 'WALAPAI': 899, 'YAVAPAI': 900,
    'CHUMASH': 901, 'TONKAWA': 902, 'YUCHI': 903, 'CROW': 904, 'HIDATSA': 905,
    'MANDAN': 906, 'DAKOTA': 907, 'CHIWERE': 908, 'WINNEBAGO': 909,
    'KANSA': 910, 'OMAHA': 911, 'OSAGE': 912, 'PONCA': 913, 'QUAPAW': 914,
    'ALABAMA': 915, 'CHOCTAW': 916, 'MIKASUKI': 917, 'HICHITA': 918,
    'KOASATI': 919, 'MUSKOGEE': 920, 'CHETEMACHA': 921, 'YUKI': 922,
    'WAPPO': 923,
    'KERES': 924, 'IROQUOIS': 925, 'MOHAWK': 926, 'ONEIDA': 927,
    'ONONDAGA': 928,
    'CAYUGA': 929, 'SENECA': 930, 'TUSCARORA': 931, 'WYANDOT': 932,
    'CHEROKEE': 933,
    'ARIKARA': 934, 'CADDO': 935, 'PAWNEE': 936, 'WICHITA': 937,
    'COMANCHE': 938,
    'MONO': 939, 'PAIUTE': 940, 'NORTHERN_PAIUTE': 941, 'SOUTHERN_PAIUTE': 942,
    'CHEMEHUEVI': 943, 'KAWAIISU': 944, 'UTE': 945, 'SHOSHONI': 946,
    'PANAMINT': 947, 'HOPI': 948, 'CAHUILLA': 949, 'CUPENO': 950,
    'LUISENO': 951,
    'SERRANO': 952, 'TUBATULABAL': 953, 'PIMA': 954, 'YAQUI': 955,
    'AZTECAN': 956,
    'PICURIS': 959, 'TIWA': 960, 'SANDIA': 961, 'TEWA': 962,
    'TOWA': 963, 'ZUNI': 964,
    'CHINOOK_JARGON': 965, 'AMERICAN_INDIAN': 966, 'MISUMALPAN': 967,
    'MAYAN_LANGUAGES': 968, 'TARASCAN': 969, 'MAPUCHE': 970,
    'OTO_MANGUEAN': 971,
    'QUECHUA': 972, 'AYMARA': 973, 'ARAWAKIAN': 974, 'CHIBCHAN': 975,
    'TUPI_GUARANI': 976, 'JICARILLA': 977, 'CHIRICAHUA': 978, 'SAN_CARLOS': 979,
    'KIOWA_APACHE': 980, 'KALISPEL': 981, 'SPOKANE': 982, 'NOT_REPORTED': 999})
class LanguageParser(object):
    """The language data is spread over two fields so we use two parsers here
    and combine their output."""
    def __init__(self):
        # This parses the languages they speak *if* English isn't their primary
        # language.
        self.__non_english_lang_parser = pv.RemapEnumParser(
                ((range(2, 601), LANGUAGE.NOT_IN_UNIVERSE),
                 (range(983, 998), LANGUAGE.NOT_SPECIFIED),
                 (range(832, 833), LANGUAGE.NOOTKA)),
                LANGUAGE, 65, 68)
        # This parses a field which is a 1 if they don't speak English, a 2 if
        # they do, and a None if they're under 5 years old and thus "don't
        # count".
        self.__is_english_int_parser = pv.IntParser(63, 64, allow_empty = True)

    def parse(self, line):
        # See comments in __init__ for an explanation of the returned values and
        # their meaning.
        is_english_int = self.__is_english_int_parser.parse(line)
        non_english_lang = self.__non_english_lang_parser.parse(line)
        if (is_english_int == 2):
            assert non_english_lang == LANGUAGE.NOT_IN_UNIVERSE
            return LANGUAGE.ENGLISH
        elif is_english_int is None:
            assert non_english_lang == LANGUAGE.NOT_IN_UNIVERSE
            return non_english_lang
        else:
            assert is_english_int == 1
            return non_english_lang

    def source(self):
        return pv.RECORD_SOURCE.PERSON

LANGUAGE_PARSER = LanguageParser()
LANGUAGE_MANIPULATOR = pv.CategoricalManipulator(
        LANGUAGE, 'Language Spoken at Home')

# Note that IntParser maps the 'null' value (0) to integer 0
# This will get in the way for neural-net learning, and so
# we may want to change it back to IntParserWithNull for
# that stype of learning.
HOURS_WORKED_PARSER = pv.IntParser(240, 242)
HOURS_WORKED_MANIPULATOR = pv.IntManipulator('Hours per week worked.')

# Note that IntParser maps the 'null' value (0) to integer 0
# This will get in the way for neural-net learning, and so
# we may want to change it back to IntParserWithNull for
# that stype of learning.
WEEKS_WORKED_PARSER = pv.IntParser(237, 239)
WEEKS_WORKED_MANIPULATOR = pv.IntManipulator('Weeks worked last year')

## A full record handler for these variables
#SPAR_VARS = Enum('STATE', 'SEX', 'AGE', 'RACE', 'MARITAL_STATUS',
#        'GRADE_ENROLLED', 'CITIZENSHIP', 'INCOME', 'MILITARY_SERVICE',
#        'LANGUAGE', 'HOURS_WORKED', 'WEEKS_WORKED')

PUMS_VARS_DICT = {
        VARS.STATE: (STATE_PARSER, STATE_MANIPULATOR),
        VARS.SEX: (SEX_PARSER, SEX_MANIPULATOR),
        VARS.AGE: (AGE_PARSER, AGE_MANIPULATOR),
        VARS.RACE: (RACE_PARSER, RACE_MANIPULATOR),
        VARS.MARITAL_STATUS: (MARITAL_STATUS_PARSER,
            MARITAL_STATUS_MANIPULATOR),
        VARS.GRADE_ENROLLED: (GRADE_ENROLLED_PARSER,
            GRADE_ENROLLED_MANIPULATOR),
        VARS.EDUCATION: (EDUCATION_PARSER, EDUCATION_MANIPULATOR),
        VARS.CITIZENSHIP: (CITIZENSHIP_PARSER, CITIZENSHIP_MANIPULATOR),
        VARS.INCOME: (INCOME_PARSER, INCOME_MANIPULATOR),
        VARS.MILITARY_SERVICE: (MILITARY_SERVICE_PARSER,
            MILITARY_SERVICE_MANIPULATOR),
        VARS.LANGUAGE: (LANGUAGE_PARSER, LANGUAGE_MANIPULATOR),
        VARS.HOURS_WORKED: (HOURS_WORKED_PARSER,
            HOURS_WORKED_MANIPULATOR),
        VARS.WEEKS_WORKED: (WEEKS_WORKED_PARSER,
            WEEKS_WORKED_MANIPULATOR),
        }



SPAR_RECORD_HANDLER = PUMSRecordHandler(PUMS_VARS_DICT)



############################################################################
#
# Uniform definitions for variables
#
##############################################################################

# This section contains all 'uniform' defintions for varaibles: functions and
# such which are well-defined for each variable, and can be isolated to that
# variable. These definitions need to come last as many of their internals 
# depend on the Enum defintions above.


# Functions to convert var-values into various formats. For the moment,
# this is just strings for the LineRawInserter, but this may be expanded
# in the future

# helpers

converter_types = ['to_line_raw', 'to_csv', 'to_agg_fmt']
ConverterCollection = collections.namedtuple('ConverterCollection', 
                                             converter_types)
def _str_to_raw_format(string):
    '''
    Internal helper function to format strings in the line-raw format.
    '''
    return "RAW\n%s\n%sENDRAW" % (len(string), string)

# Enum types
def make_converters_from_enum(enum):
    '''
    Convert an Enum into a ConverterCollection.
    '''
    return ConverterCollection(enum.to_string, enum.to_string, 
                               enum.to_string_upper)


# noop converter
def no_conversion(obj):
    '''
    Place holder converter which does nothing
    '''
    return obj
        
# string types

def str_to_upper(str_obj):
    '''
    Converts str to uppercase
    '''
    return str_obj.upper()

# datetime types

def date_to_str(date_obj):
    '''
    Converts a datetime.date-typed var to the right string format.
    '''
    # NOTE: UPDATE data_generation/sanitization.py if this changes!
    return date_obj.isoformat()

# bytearray types

def byte_array_to_line_raw(bytearray_obj):
    '''
    Converts a bytearray-typed var to line-raw format.
    '''
    byte_string_fmt = str(bytearray_obj)
    return _str_to_raw_format(byte_string_fmt)

def byte_array_to_csv(bytearray_obj):
    '''
    Converts a bytearray-typed var to csv-file format.
    '''
    return str(bytearray_obj).encode('hex')

# text-field types (word-stem pair lists)

def text_field_to_line_raw(generated_text):
    ''' Converts the word portion of the test fields into line raw format '''
    string_fmt = str(generated_text)
    return _str_to_raw_format(string_fmt)

def text_to_upper_str(generated_text):
    '''
    Converts text fields words to a single uppercased string by joining all the 
    words into one string
    '''
    return generated_text.upper()


generated_text_converters = ConverterCollection(text_field_to_line_raw,
                                                str,
                                                text_to_upper_str)


# master list of converters


VAR_CONVERTERS = {
    #ints
    VARS.ID : ConverterCollection(str, str, no_conversion),
    VARS.AGE : ConverterCollection(str, str, no_conversion),
    VARS.INCOME : ConverterCollection(str, str, no_conversion),
    VARS.HOURS_WORKED : ConverterCollection(str, str, no_conversion),
    VARS.WEEKS_WORKED : ConverterCollection(str, str, no_conversion),
    VARS.FOO : ConverterCollection(str, str, no_conversion),
    VARS.LAST_UPDATED : ConverterCollection(str, str, no_conversion),

    #strings
    VARS.FIRST_NAME : ConverterCollection(str, str, str_to_upper),
    VARS.LAST_NAME : ConverterCollection(str, str, str_to_upper),
    VARS.SSN : ConverterCollection(str, str, str_to_upper),
    VARS.ZIP_CODE : ConverterCollection(str, str, str_to_upper),
    VARS.CITY : ConverterCollection(str, str, str_to_upper),
    VARS.STREET_ADDRESS : ConverterCollection(str, str, str_to_upper),
    
    #enums
    VARS.STATE : make_converters_from_enum(STATES),
    VARS.SEX : make_converters_from_enum(SEX),
    VARS.RACE : make_converters_from_enum(RACE),
    VARS.MARITAL_STATUS : make_converters_from_enum(MARITAL_STATUS),
    VARS.GRADE_ENROLLED : make_converters_from_enum(GRADE_ENROLLED),
    VARS.EDUCATION : make_converters_from_enum(EDUCATION),
    VARS.CITIZENSHIP : make_converters_from_enum(CITIZENSHIP),    
    VARS.MILITARY_SERVICE : make_converters_from_enum(MILITARY_SERVICE),
    VARS.LANGUAGE : make_converters_from_enum(LANGUAGE),

    # text fields
    VARS.NOTES1 : generated_text_converters,
    VARS.NOTES2 : generated_text_converters,
    VARS.NOTES3 : generated_text_converters,
    VARS.NOTES4 : generated_text_converters,

    # xml
    VARS.XML : ConverterCollection(str, str, no_conversion),

    # other
    VARS.DOB : ConverterCollection(date_to_str, date_to_str, no_conversion),
    VARS.FINGERPRINT : ConverterCollection(byte_array_to_line_raw,
                                           byte_array_to_csv, byte_array_to_csv),
    }

VAR_TO_ENUM = {
    VARS.STATE : STATES,
    VARS.SEX : SEX,
    VARS.RACE : RACE,
    VARS.MARITAL_STATUS : MARITAL_STATUS,
    VARS.GRADE_ENROLLED : GRADE_ENROLLED,
    VARS.EDUCATION : EDUCATION,
    VARS.CITIZENSHIP : CITIZENSHIP,
    VARS.MILITARY_SERVICE : MILITARY_SERVICE,
    VARS.LANGUAGE : LANGUAGE
    }

